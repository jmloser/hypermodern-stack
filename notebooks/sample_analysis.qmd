---
title: "Sample Data Analysis with Hypermodern Python Stack"
format: html
jupyter: python3
---

## Introduction

This notebook demonstrates the capabilities of our hypermodern Python stack for data science and visualization.

```{python}
# Import libraries from our stack
import numpy as np
import pandas as pd
import polars as pl
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
from rich.console import Console
from loguru import logger

console = Console()
console.print("üöÄ Welcome to the Hypermodern Python Stack!", style="bold blue")
```

## Generate Sample Data

```{python}
# Generate sample data using numpy
np.random.seed(42)
n_samples = 1000

data = {
    'timestamp': pd.date_range('2024-01-01', periods=n_samples, freq='1H'),
    'value': np.cumsum(np.random.randn(n_samples)) * 10,
    'category': np.random.choice(['A', 'B', 'C'], n_samples),
    'feature_1': np.random.randn(n_samples),
    'feature_2': np.random.randn(n_samples) * 2 + 1
}

# Create both pandas and polars DataFrames for comparison
df_pandas = pd.DataFrame(data)
df_polars = pl.DataFrame(data)

console.print(f"Created DataFrames with {len(df_pandas)} rows", style="green")
```

## Data Analysis with Polars (Fast!)

```{python}
# Demonstrate Polars performance and syntax
polars_summary = (
    df_polars
    .group_by('category')
    .agg([
        pl.col('value').mean().alias('mean_value'),
        pl.col('value').std().alias('std_value'),
        pl.col('feature_1').median().alias('median_feature_1'),
        pl.len().alias('count')
    ])
    .sort('mean_value', descending=True)
)

print("üìä Summary by Category (using Polars):")
print(polars_summary)
```

## Interactive Visualizations with Plotly

```{python}
# Time series plot
fig_ts = px.line(df_pandas, x='timestamp', y='value', color='category',
                title='Time Series Data by Category')
fig_ts.show()
```

```{python}
# Correlation scatter plot with interactive features
fig_scatter = px.scatter(df_pandas, x='feature_1', y='feature_2', 
                        color='category', size='value',
                        hover_data=['timestamp'],
                        title='Feature Correlation (Interactive)')
fig_scatter.show()
```

```{python}
# 3D scatter plot
fig_3d = px.scatter_3d(df_pandas.sample(200), x='feature_1', y='feature_2', z='value',
                      color='category', title='3D Feature Space')
fig_3d.show()
```

## Statistical Analysis with scipy and statsmodels

```{python}
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Prepare features for modeling
X = df_pandas[['feature_1', 'feature_2']].values
y = df_pandas['value'].values

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a simple model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Model performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

console.print(f"Model Performance:", style="bold")
console.print(f"  MSE: {mse:.4f}", style="cyan")
console.print(f"  R¬≤: {r2:.4f}", style="cyan")
```

```{python}
# Create prediction vs actual plot
fig_pred = go.Figure()
fig_pred.add_trace(go.Scatter(x=y_test, y=y_pred, mode='markers',
                             name='Predictions',
                             marker=dict(color='blue', opacity=0.6)))
fig_pred.add_trace(go.Scatter(x=[y_test.min(), y_test.max()], 
                             y=[y_test.min(), y_test.max()],
                             mode='lines', name='Perfect Prediction',
                             line=dict(color='red', dash='dash')))
fig_pred.update_layout(title='Model Predictions vs Actual Values',
                      xaxis_title='Actual Values',
                      yaxis_title='Predicted Values')
fig_pred.show()
```

## Advanced Visualization with Seaborn

```{python}
# Statistical plots using seaborn
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
sns.boxplot(data=df_pandas, x='category', y='value')
plt.title('Value Distribution by Category')

plt.subplot(1, 3, 2)
sns.histplot(data=df_pandas, x='feature_1', hue='category', alpha=0.7)
plt.title('Feature 1 Distribution')

plt.subplot(1, 3, 3)
correlation_matrix = df_pandas[['value', 'feature_1', 'feature_2']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Feature Correlation Matrix')

plt.tight_layout()
plt.show()
```

## Data Validation and Quality Checks

```{python}
# Basic data quality assessment
quality_report = {
    'total_rows': len(df_pandas),
    'missing_values': df_pandas.isnull().sum().to_dict(),
    'data_types': df_pandas.dtypes.to_dict(),
    'memory_usage': df_pandas.memory_usage(deep=True).sum(),
    'duplicate_rows': df_pandas.duplicated().sum()
}

console.print("üìã Data Quality Report:", style="bold")
for key, value in quality_report.items():
    console.print(f"  {key}: {value}", style="white")
```

## Performance Comparison: Pandas vs Polars

```{python}
import time

def time_operation(func, name):
    start = time.time()
    result = func()
    end = time.time()
    console.print(f"{name}: {end - start:.4f} seconds", style="yellow")
    return result

# Compare groupby operations
console.print("‚ö° Performance Comparison:", style="bold")

def pandas_groupby():
    return df_pandas.groupby('category')['value'].agg(['mean', 'std', 'count'])

def polars_groupby():
    return df_polars.group_by('category').agg([
        pl.col('value').mean().alias('mean'),
        pl.col('value').std().alias('std'),
        pl.len().alias('count')
    ])

pandas_result = time_operation(pandas_groupby, "Pandas groupby")
polars_result = time_operation(polars_groupby, "Polars groupby")
```

## Conclusion

This notebook demonstrates the power of our hypermodern Python stack:

- üöÄ **Fast data processing** with Polars
- üìä **Interactive visualizations** with Plotly  
- üî¨ **Statistical analysis** with scipy and scikit-learn
- üé® **Beautiful plots** with Seaborn and Matplotlib
- üõ†Ô∏è **Rich terminal output** for better development experience

The stack provides everything needed for modern data science and backend development!
